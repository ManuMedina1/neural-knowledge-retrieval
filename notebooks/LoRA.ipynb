{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758951c9",
   "metadata": {},
   "source": [
    "# Práctica II: Uso de modelos Transformers (Fine-tunning LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914299e1",
   "metadata": {},
   "source": [
    "## 0. Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b72edf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import list_models, model_info\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from steam_reviews import ReviewLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f5618",
   "metadata": {},
   "source": [
    "# 1. Carga del dataset\n",
    "Hemos decidido valorar reseñas para hacer análisis de sentimiento, pero será sobre un videojuego el cual es uno que a uno del grupo le gusta mucho: Geometry Dash. Como en hugging face no hay datos de reseñas de Steam (o al menos, no encontramos), vamos a apoyarnos en una herramienta que nos permitirá extraer reseñas de Steam: steam-reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "02abd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias extras a instalar\n",
    "# !pip install steam-reviews\n",
    "# !pip install sentencepiece protobuf tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb60652",
   "metadata": {},
   "source": [
    "Ahora, esta es la idea: Vamos a descargar muchas reseñas del juego, vamos a darles un valor (para hacerlo simple, haremos un **análisis de sentimiento, donde solo tendremos 2 valores posibles: Positivo o negativo**). Para ello, necesitamos la ID del juego, el cual es '322170'. Con esto, podemos empezar a usar la librería que descargamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "98007e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que devuelve un objeto con reseñas del juego\n",
    "def obtener_tipo_reseñas(id_juego, tipo_reseña, num_reseñas=10000):\n",
    "\n",
    "    # Instanciamos el objeto que nos descargara las reseñas\n",
    "    loader = ReviewLoader()\n",
    "\n",
    "    # Lo configuramos\n",
    "    loader.set_language('english')  # idioma de las reseñas\n",
    "    loader.set_review_type(tipo_reseña)  # tipo de reseñas: positivas o negativas\n",
    "    loader.set_num_per_page(100)  # cuantas reseñas por pagina\n",
    "\n",
    "    # Realizamos la descarga de las reseñas\n",
    "    reviews = loader.load_batch_from_api([id_juego], num=num_reseñas)[0].review_dict()\n",
    "\n",
    "    # Devolvemos las reseñas\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "be01b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the request. The game has total 300000 reviews, and will only get 10000 reviews.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:32<00:00, 303.30it/s]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the request. The game has total 300000 reviews, and will only get 10000 reviews.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9997/10000 [00:34<00:00, 300.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests count is 100, will wait for 57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10097it [01:32, 109.39it/s]                          \n"
     ]
    }
   ],
   "source": [
    "# Configuramos los datos para extraer la informacion de las reseñas\n",
    "id_geometry = 322170\n",
    "\n",
    "# Obtenemos las reseñas\n",
    "positive_reviews = obtener_tipo_reseñas(id_geometry, 'positive')\n",
    "negative_reviews = obtener_tipo_reseñas(id_geometry, 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbe2aa",
   "metadata": {},
   "source": [
    "Veamos como son las reseñas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5e45e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra informacion de una reseña\n",
    "def mostrar_info_reseña(reseña):\n",
    "\n",
    "    # Mostramos la reseña\n",
    "    print(f'Idioma: {reseña[\"language\"]}')\n",
    "    print(f'¿Positiva?: {reseña[\"voted_up\"]}')\n",
    "    print(f'Reseña:\\n{reseña[\"review\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "166aa660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Informacion reseñas ===============\n",
      "Total de reseñas: 20000\n",
      "Total reseñas positivas: 10000\n",
      "Total reseñas negativas: 10000\n",
      "=============== Informacion reseña positiva ===============\n",
      "Idioma: english\n",
      "¿Positiva?: True\n",
      "Reseña:\n",
      "I lost all my gameplay after the update was released (\n",
      "=============== Informacion reseña negativa ===============\n",
      "Idioma: english\n",
      "¿Positiva?: False\n",
      "Reseña:\n",
      "bad stupiud baD, O;PTION FOR CHECKPOINTS (SPOILER: THERE IS NON) NOT ADVISED FOR TWITCHY FINGERED PLAYERS OR YOU WILL DIE AND DIE AND DIE FOR 6 YEARS STRAIGHT BECAUSE ITS STUPIUD\n"
     ]
    }
   ],
   "source": [
    "# Extraemos una reseña positiva y otra negativa\n",
    "first_positive_review = positive_reviews[0]\n",
    "forst_negative_review = negative_reviews[0]\n",
    "\n",
    "# Mostramos numero de reseñas\n",
    "print('=' * 15, 'Informacion reseñas', '=' * 15)\n",
    "print(f'Total de reseñas: {len(positive_reviews) + len(negative_reviews)}')\n",
    "print(f'Total reseñas positivas: {len(positive_reviews)}')\n",
    "print(f'Total reseñas negativas: {len(negative_reviews)}')\n",
    "\n",
    "# Mostramos las infos basicas de las reseñas\n",
    "print('=' * 15, 'Informacion reseña positiva', '=' * 15)\n",
    "mostrar_info_reseña(first_positive_review)\n",
    "print('=' * 15, 'Informacion reseña negativa', '=' * 15)\n",
    "mostrar_info_reseña(forst_negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7981d",
   "metadata": {},
   "source": [
    "Con esto, ya podemos construir un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "18f59129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I lost all my gameplay after the update was re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad stupiud baD, O;PTION FOR CHECKPOINTS (SPOI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i came to this game many times and now my keyb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shit fuck this game</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEST GAME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>still i don't like this shit game. and i want ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>fun.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>I hate this game</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>love it but i hate that i cant play it on my c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "0      I lost all my gameplay after the update was re...      1\n",
       "1      bad stupiud baD, O;PTION FOR CHECKPOINTS (SPOI...      0\n",
       "2      i came to this game many times and now my keyb...      1\n",
       "3                                    shit fuck this game      0\n",
       "4                                              BEST GAME      1\n",
       "...                                                  ...    ...\n",
       "19995  still i don't like this shit game. and i want ...      0\n",
       "19996                                               fun.      1\n",
       "19997                                   I hate this game      0\n",
       "19998  love it but i hate that i cant play it on my c...      1\n",
       "19999                                                  r      0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el diccionario final\n",
    "reviews = {'reviews': list(), 'label': list()}\n",
    "\n",
    "# Juntamos ambas reseñas y formamos un dataframe\n",
    "for positive_review, negative_review in zip(positive_reviews, negative_reviews):\n",
    "\n",
    "    # Añadimos la review positiva\n",
    "    reviews['reviews'].append(positive_review['review'])\n",
    "    reviews['label'].append(1 if positive_review['voted_up'] else 0)\n",
    "\n",
    "    # Ahora la negativa\n",
    "    reviews['reviews'].append(negative_review['review'])\n",
    "    reviews['label'].append(1 if negative_review['voted_up'] else 0)\n",
    "\n",
    "# Pasamos esto a un dataframe\n",
    "reviews_dataframe = pd.DataFrame(reviews)\n",
    "reviews_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d50de",
   "metadata": {},
   "source": [
    "Pero para los modelos de hugging face, hay que pasarlos a un tipo en especial: Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8f334a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['reviews', 'label'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_hugging_face = Dataset.from_pandas(reviews_dataframe)\n",
    "reviews_hugging_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc005fa",
   "metadata": {},
   "source": [
    "## ¿Por qué este dataset?\n",
    "Es verdad que no está nada relacionado con lo que estudiamos, pero tener en cuenta que este juego es muy reciente, por lo cual **no hay información sobre estas reseñas en hugging_face.** Es verdad que la complejidad de entrenar el modelo no será mucha, ya que Steam solo tiene 2 rangos de clasificación: Positivo y negativo. Pero hay comentarios que son muy extraños e inimaginables, lo cuál puede suponer un reto a la hora de entrenar el modelo. Más justificación en el PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b91424",
   "metadata": {},
   "source": [
    "# 2. Selección de modelos\n",
    "Es importante elegir modelos **de la familia encoder only,** ya que nuestra tarea es **sentiment analyzer.** No buscamos generar nuevas reseñas, ni tampoco traducirlas o resumirlas. Aunque veremos que se puede generar reseñas, no es el foco principal. Nos dedicaremos a **analizar las reseñas del juego** y para ello solo necesitamos un encoder-only, que nos sacará el sentimiento (hay que entrenarlo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec39fc",
   "metadata": {},
   "source": [
    "## 2.1. Búsqueda rápida de modelos\n",
    "Hugging face da la facilidad de buscar modelos con filtros, por lo cual, buscaremos los mejores modelos encoders (no especializados) para esta tarea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fbe2f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos los modelos\n",
    "modelos_sa = list(\n",
    "        list_models(\n",
    "        filter='fill-mask',\n",
    "        sort='downloads',\n",
    "        direction=-1,\n",
    "        limit=25\n",
    "    )\n",
    ")\n",
    "\n",
    "# Obtenemos los nombres para ver sus infos\n",
    "nombres_modelos_sa = [nombre.id for nombre in modelos_sa]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc2a66",
   "metadata": {},
   "source": [
    "Estos son los 25 mejores modelos según 'descargas' para análisis de sentimiento en inglés. Vamos a comparar sus Model Cards solo si no están especializados (y si no los hemos visto en clase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c5506999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos que no podemos usar (vistos en clase, sacado por chatgpt)\n",
    "modelos_vistos_en_clase = {\n",
    "    # --- Notebook 4.1: Introducción a Transformers ---\n",
    "    \"bert-base-uncased\",       # Usado para ejemplos de Fill-Mask y Tokenización\n",
    "    \"gpt2\",                    # Usado para Text Generation\n",
    "    \"t5-small\",                # Usado para Traducción/Resumen\n",
    "    \"distilbert-base-uncased\", # Mencionado y usado en pipelines\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\", # Usado implícitamente en el pipeline(\"sentiment-analysis\")\n",
    "\n",
    "    # --- Notebook 4.2a: Fine-Tuning con LoRA ---\n",
    "    \"distilbert-base-uncased\", # ¡CRÍTICO! Este es el modelo base del ejercicio. NO LO USES.\n",
    "    \"roberta-base-openai-detector\", # A veces aparece en versiones antiguas de este ejercicio, lo añado por seguridad\n",
    "\n",
    "    # --- Notebook 4.2b: RAG (Retrieval Augmented Generation) ---\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\", # Usado para Embeddings (Vector DB)\n",
    "    \"google/flan-t5-small\",    # Usado como el LLM generador\n",
    "    \"facebook/rag-token-nq\",   # A veces mencionado en teoría de RAG\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para obtener la informacion de un modelo con model info\n",
    "def obtener_informacion_modelo(id_modelo):\n",
    "\n",
    "    # Obtenemos la informacion del modelo\n",
    "    info_modelo = model_info(id_modelo)\n",
    "\n",
    "    # Preparamos algunos datos\n",
    "    card_data = getattr(info_modelo, 'card_data', 'None')\n",
    "    licencia = card_data['license'] if card_data is not None else 'None'\n",
    "\n",
    "    # Organizamos la informacion en un dict\n",
    "    informacion = {\n",
    "        'nombre': getattr(info_modelo, 'id', 'None'),\n",
    "        'autor': getattr(info_modelo, 'author', 'None'),\n",
    "        'tarea': getattr(info_modelo, 'pipeline_tag', 'None'),\n",
    "        'fecha-creacion': getattr(info_modelo, 'created_at', 'None'),\n",
    "        'fecha-ultima-acualizacion': getattr(info_modelo, 'last_modified', 'None'),\n",
    "        'descargas': getattr(info_modelo, 'downloads', 'None'),\n",
    "        'likes': getattr(info_modelo, 'likes', 'None'),\n",
    "        'tags': ', '.join(getattr(info_modelo, 'tags', 'None'),),\n",
    "        'licencia': licencia\n",
    "    }\n",
    "\n",
    "    return informacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23dce033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que evalua si un modelo lo podemos usar\n",
    "def can_use_model(informacion_modelo):\n",
    "\n",
    "    # Compromabmos si el nombre contiene distilbert (visto en clase)\n",
    "    nombre_modelo = informacion_modelo['nombre'].lower().split('/')[1]\n",
    "    if nombre_modelo in modelos_vistos_en_clase:  # Evitamos usar los modelos vistos en clase\n",
    "        return False\n",
    "    \n",
    "    # Comprobamos si los tags no son solo fill-mask\n",
    "    if informacion_modelo['tarea'] != 'fill-mask':\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "378631d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que devuelve un dataframe comparativo\n",
    "def obtener_dataframe_informativo(modelos, funcion_informacion):\n",
    "\n",
    "    # Lista de dicts de los modelos\n",
    "    list_info_modelos = list()\n",
    "\n",
    "    # Creamos un dataframe para ver la informacion basica de los modelos\n",
    "    for nombre_modelo in modelos:\n",
    "\n",
    "        # Obtenemos la informacion del modelo\n",
    "        informacion_modelo = funcion_informacion(nombre_modelo)\n",
    "\n",
    "        # Vemos si esta pre-entrenado: en caso de estarlo, descartamos\n",
    "        if not can_use_model(informacion_modelo):\n",
    "            continue\n",
    "\n",
    "        # Añadimos a la lista\n",
    "        list_info_modelos.append(informacion_modelo)\n",
    "\n",
    "    # Creamos el dataframe\n",
    "    comparativa_modelos = pd.DataFrame(list_info_modelos)\n",
    "    return comparativa_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8e33e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>autor</th>\n",
       "      <th>tarea</th>\n",
       "      <th>fecha-creacion</th>\n",
       "      <th>fecha-ultima-acualizacion</th>\n",
       "      <th>descargas</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "      <th>licencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-large</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 12:47:04+00:00</td>\n",
       "      <td>14572286</td>\n",
       "      <td>256</td>\n",
       "      <td>transformers, pytorch, tf, jax, onnx, safetens...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 12:39:28+00:00</td>\n",
       "      <td>8977612</td>\n",
       "      <td>534</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, safetens...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FacebookAI/xlm-roberta-base</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 12:48:21+00:00</td>\n",
       "      <td>7438379</td>\n",
       "      <td>762</td>\n",
       "      <td>transformers, pytorch, tf, jax, onnx, safetens...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-bert/bert-base-multilingual-cased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 11:05:41+00:00</td>\n",
       "      <td>5788701</td>\n",
       "      <td>555</td>\n",
       "      <td>transformers, pytorch, tf, jax, safetensors, b...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google-bert/bert-base-multilingual-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 11:06:00+00:00</td>\n",
       "      <td>4954656</td>\n",
       "      <td>142</td>\n",
       "      <td>transformers, pytorch, tf, jax, safetensors, b...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nlpaueb/legal-bert-base-uncased</td>\n",
       "      <td>nlpaueb</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2022-04-28 14:42:50+00:00</td>\n",
       "      <td>4264760</td>\n",
       "      <td>288</td>\n",
       "      <td>transformers, pytorch, tf, jax, bert, pretrain...</td>\n",
       "      <td>cc-by-sa-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google-bert/bert-base-cased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 11:02:26+00:00</td>\n",
       "      <td>3522011</td>\n",
       "      <td>336</td>\n",
       "      <td>transformers, pytorch, tf, jax, safetensors, b...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FacebookAI/xlm-roberta-large</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 12:48:30+00:00</td>\n",
       "      <td>3256300</td>\n",
       "      <td>475</td>\n",
       "      <td>transformers, pytorch, tf, jax, onnx, safetens...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>emilyalsentzer/Bio_ClinicalBERT</td>\n",
       "      <td>emilyalsentzer</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2024-12-03 20:22:45+00:00</td>\n",
       "      <td>2921734</td>\n",
       "      <td>400</td>\n",
       "      <td>transformers, pytorch, tf, jax, bert, fill-mas...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>facebook/esm2_t33_650M_UR50D</td>\n",
       "      <td>facebook</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-09-27 14:36:16+00:00</td>\n",
       "      <td>2023-03-21 15:05:12+00:00</td>\n",
       "      <td>2056394</td>\n",
       "      <td>59</td>\n",
       "      <td>transformers, pytorch, tf, safetensors, esm, f...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>microsoft/deberta-v3-base</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2022-09-22 12:34:19+00:00</td>\n",
       "      <td>1992303</td>\n",
       "      <td>376</td>\n",
       "      <td>transformers, pytorch, tf, rust, deberta-v2, d...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google-bert/bert-base-chinese</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2025-07-03 11:58:48+00:00</td>\n",
       "      <td>1681071</td>\n",
       "      <td>1334</td>\n",
       "      <td>transformers, pytorch, tf, jax, safetensors, b...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>distilbert/distilroberta-base</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 11:09:58+00:00</td>\n",
       "      <td>1588349</td>\n",
       "      <td>164</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, safetens...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dandelin/vilt-b32-mlm</td>\n",
       "      <td>dandelin</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2022-07-06 12:18:37+00:00</td>\n",
       "      <td>1581478</td>\n",
       "      <td>12</td>\n",
       "      <td>transformers, pytorch, vilt, fill-mask, arxiv:...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>facebook/esm2_t6_8M_UR50D</td>\n",
       "      <td>facebook</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-09-26 18:44:55+00:00</td>\n",
       "      <td>2023-03-21 15:05:17+00:00</td>\n",
       "      <td>1446219</td>\n",
       "      <td>24</td>\n",
       "      <td>transformers, pytorch, tf, safetensors, esm, f...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>microsoft/BiomedNLP-BiomedBERT-base-uncased-ab...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2023-11-06 18:04:15+00:00</td>\n",
       "      <td>1163380</td>\n",
       "      <td>83</td>\n",
       "      <td>transformers, pytorch, jax, bert, fill-mask, e...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dccuchile/bert-base-spanish-wwm-uncased</td>\n",
       "      <td>dccuchile</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2024-01-18 01:46:43+00:00</td>\n",
       "      <td>979426</td>\n",
       "      <td>72</td>\n",
       "      <td>transformers, pytorch, tf, jax, bert, fill-mas...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>distilbert/distilbert-base-multilingual-cased</td>\n",
       "      <td>distilbert</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-05-06 13:46:54+00:00</td>\n",
       "      <td>867073</td>\n",
       "      <td>224</td>\n",
       "      <td>transformers, pytorch, tf, onnx, safetensors, ...</td>\n",
       "      <td>apache-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>almanach/camembert-base</td>\n",
       "      <td>almanach</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2025-06-23 14:02:30+00:00</td>\n",
       "      <td>815907</td>\n",
       "      <td>94</td>\n",
       "      <td>transformers, pytorch, tf, safetensors, camemb...</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InstaDeepAI/nucleotide-transformer-500m-human-ref</td>\n",
       "      <td>InstaDeepAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2023-04-04 21:37:57+00:00</td>\n",
       "      <td>2024-07-22 09:23:44+00:00</td>\n",
       "      <td>777031</td>\n",
       "      <td>14</td>\n",
       "      <td>transformers, pytorch, tf, joblib, esm, fill-m...</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               nombre           autor  \\\n",
       "0                            FacebookAI/roberta-large      FacebookAI   \n",
       "1                             FacebookAI/roberta-base      FacebookAI   \n",
       "2                         FacebookAI/xlm-roberta-base      FacebookAI   \n",
       "3            google-bert/bert-base-multilingual-cased     google-bert   \n",
       "4          google-bert/bert-base-multilingual-uncased     google-bert   \n",
       "5                     nlpaueb/legal-bert-base-uncased         nlpaueb   \n",
       "6                         google-bert/bert-base-cased     google-bert   \n",
       "7                        FacebookAI/xlm-roberta-large      FacebookAI   \n",
       "8                     emilyalsentzer/Bio_ClinicalBERT  emilyalsentzer   \n",
       "9                        facebook/esm2_t33_650M_UR50D        facebook   \n",
       "10                          microsoft/deberta-v3-base       microsoft   \n",
       "11                      google-bert/bert-base-chinese     google-bert   \n",
       "12                      distilbert/distilroberta-base      distilbert   \n",
       "13                              dandelin/vilt-b32-mlm        dandelin   \n",
       "14                          facebook/esm2_t6_8M_UR50D        facebook   \n",
       "15  microsoft/BiomedNLP-BiomedBERT-base-uncased-ab...       microsoft   \n",
       "16            dccuchile/bert-base-spanish-wwm-uncased       dccuchile   \n",
       "17      distilbert/distilbert-base-multilingual-cased      distilbert   \n",
       "18                            almanach/camembert-base        almanach   \n",
       "19  InstaDeepAI/nucleotide-transformer-500m-human-ref     InstaDeepAI   \n",
       "\n",
       "        tarea            fecha-creacion fecha-ultima-acualizacion  descargas  \\\n",
       "0   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 12:47:04+00:00   14572286   \n",
       "1   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 12:39:28+00:00    8977612   \n",
       "2   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 12:48:21+00:00    7438379   \n",
       "3   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 11:05:41+00:00    5788701   \n",
       "4   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 11:06:00+00:00    4954656   \n",
       "5   fill-mask 2022-03-02 23:29:05+00:00 2022-04-28 14:42:50+00:00    4264760   \n",
       "6   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 11:02:26+00:00    3522011   \n",
       "7   fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 12:48:30+00:00    3256300   \n",
       "8   fill-mask 2022-03-02 23:29:05+00:00 2024-12-03 20:22:45+00:00    2921734   \n",
       "9   fill-mask 2022-09-27 14:36:16+00:00 2023-03-21 15:05:12+00:00    2056394   \n",
       "10  fill-mask 2022-03-02 23:29:05+00:00 2022-09-22 12:34:19+00:00    1992303   \n",
       "11  fill-mask 2022-03-02 23:29:04+00:00 2025-07-03 11:58:48+00:00    1681071   \n",
       "12  fill-mask 2022-03-02 23:29:04+00:00 2024-02-19 11:09:58+00:00    1588349   \n",
       "13  fill-mask 2022-03-02 23:29:05+00:00 2022-07-06 12:18:37+00:00    1581478   \n",
       "14  fill-mask 2022-09-26 18:44:55+00:00 2023-03-21 15:05:17+00:00    1446219   \n",
       "15  fill-mask 2022-03-02 23:29:05+00:00 2023-11-06 18:04:15+00:00    1163380   \n",
       "16  fill-mask 2022-03-02 23:29:05+00:00 2024-01-18 01:46:43+00:00     979426   \n",
       "17  fill-mask 2022-03-02 23:29:04+00:00 2024-05-06 13:46:54+00:00     867073   \n",
       "18  fill-mask 2022-03-02 23:29:04+00:00 2025-06-23 14:02:30+00:00     815907   \n",
       "19  fill-mask 2023-04-04 21:37:57+00:00 2024-07-22 09:23:44+00:00     777031   \n",
       "\n",
       "    likes                                               tags         licencia  \n",
       "0     256  transformers, pytorch, tf, jax, onnx, safetens...              mit  \n",
       "1     534  transformers, pytorch, tf, jax, rust, safetens...              mit  \n",
       "2     762  transformers, pytorch, tf, jax, onnx, safetens...              mit  \n",
       "3     555  transformers, pytorch, tf, jax, safetensors, b...       apache-2.0  \n",
       "4     142  transformers, pytorch, tf, jax, safetensors, b...       apache-2.0  \n",
       "5     288  transformers, pytorch, tf, jax, bert, pretrain...     cc-by-sa-4.0  \n",
       "6     336  transformers, pytorch, tf, jax, safetensors, b...       apache-2.0  \n",
       "7     475  transformers, pytorch, tf, jax, onnx, safetens...              mit  \n",
       "8     400  transformers, pytorch, tf, jax, bert, fill-mas...              mit  \n",
       "9      59  transformers, pytorch, tf, safetensors, esm, f...              mit  \n",
       "10    376  transformers, pytorch, tf, rust, deberta-v2, d...              mit  \n",
       "11   1334  transformers, pytorch, tf, jax, safetensors, b...       apache-2.0  \n",
       "12    164  transformers, pytorch, tf, jax, rust, safetens...       apache-2.0  \n",
       "13     12  transformers, pytorch, vilt, fill-mask, arxiv:...       apache-2.0  \n",
       "14     24  transformers, pytorch, tf, safetensors, esm, f...              mit  \n",
       "15     83  transformers, pytorch, jax, bert, fill-mask, e...              mit  \n",
       "16     72  transformers, pytorch, tf, jax, bert, fill-mas...             None  \n",
       "17    224  transformers, pytorch, tf, onnx, safetensors, ...       apache-2.0  \n",
       "18     94  transformers, pytorch, tf, safetensors, camemb...              mit  \n",
       "19     14  transformers, pytorch, tf, joblib, esm, fill-m...  cc-by-nc-sa-4.0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el dataframe\n",
    "comparativa_modelos = obtener_dataframe_informativo(nombres_modelos_sa, obtener_informacion_modelo)\n",
    "comparativa_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34669a3",
   "metadata": {},
   "source": [
    "Viendo la información básica de los modelos, podemos quedarnos con 2: el de 'FacebookAI/roberta-base' y 'microsoft/deberta-v3-base', ya que estos (según ChatGPT) **no están especializados en algún dominio y tampoco en sentiment-analizer.** De paso, será interesante comparar un modelo 'actual' (última actualización de roberta: 2024) y uno 'viejito' (última actualización de deberta: 2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "291aa4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que obtiene los parametros del modelo\n",
    "def obtener_parametros_modelo(nombre_modelo):\n",
    "\n",
    "    # Obtenemos el modelo\n",
    "    modelo = AutoModelForSequenceClassification.from_pretrained(nombre_modelo)\n",
    "\n",
    "    # Obtenemos los parametros del modelo\n",
    "    parametros_modelo = sum(parametro.numel() for parametro in modelo.parameters())\n",
    "    return parametros_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278a24c",
   "metadata": {},
   "source": [
    "Vamos ahora a analizarlos más en profundidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c2bfa907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para obtener la informacion de un modelo con model info\n",
    "def obtener_informacion_avanzada(id_modelo):\n",
    "    try:\n",
    "        # IMPORTANTE: files_metadata=True es necesario para saber el peso de los archivos\n",
    "        info = model_info(id_modelo, files_metadata=True)\n",
    "    except Exception as ex:\n",
    "        return f'Error al buscar el modelo: {ex}'\n",
    "\n",
    "    # Intentamos obtener la licencia de los tags\n",
    "    licencia = 'Desconocida'\n",
    "    if info.tags:\n",
    "        for tag in info.tags:\n",
    "            if tag.startswith(\"license:\"):\n",
    "                licencia = tag.split(\":\")[1]\n",
    "                break\n",
    "\n",
    "    # Si no está en tags, miramos en card_data con seguridad\n",
    "    if licencia == 'Desconocida':\n",
    "        card_data = getattr(info, 'card_data', None)\n",
    "        if card_data and hasattr(card_data, 'get'):\n",
    "             licencia = card_data.get('license', 'Desconocida')\n",
    "\n",
    "    # Obtenemos la arquitectura, que estara dentro del diccionario 'config'\n",
    "    config = getattr(info, 'config', {}) or {}\n",
    "    arquitectura = config.get('architectures', ['Desconocida'])[0]\n",
    "    tipo_modelo = config.get('model_type', 'Desconocido')\n",
    "    \n",
    "    # Obtenemos el peso del modelo\n",
    "    peso_bytes = sum(f.size for f in info.siblings if f.size is not None)\n",
    "    peso_mb = f\"{peso_bytes / (1024 * 1024):.2f} MB\"\n",
    "    peso_gb = f\"{peso_bytes / (1024 * 1024 * 1024):.2f} GB\"\n",
    "\n",
    "    # Obtenemos las tecnicas de pre-entrenamiento\n",
    "    tecnicas_detectadas = []\n",
    "    if info.tags:\n",
    "        posibles_tecnicas = ['masked-lm', 'causal-lm', 'seq2seq', 'translation', 'token-classification']\n",
    "        for tag in info.tags:\n",
    "            if tag in posibles_tecnicas:\n",
    "                tecnicas_detectadas.append(tag)\n",
    "    \n",
    "    str_tecnicas = \", \".join(tecnicas_detectadas) if tecnicas_detectadas else \"Ver Model Card (Texto)\"\n",
    "\n",
    "    # Devolvemos todo en un diccionario\n",
    "    informacion = {\n",
    "        'nombre': info.id,\n",
    "        'autor': getattr(info, 'author', 'None'),\n",
    "        'tarea': getattr(info, 'pipeline_tag', 'None'),\n",
    "        'fecha-creacion': getattr(info, 'created_at', 'None'),\n",
    "        'fecha-ultima-acualizacion': getattr(info, 'last_modified', 'None'), \n",
    "        'arquitectura_base': arquitectura,\n",
    "        'tipo_modelo': tipo_modelo,\n",
    "        'parametros': obtener_parametros_modelo(id_modelo),\n",
    "        'peso_disco': f\"{peso_mb} ({peso_gb})\",\n",
    "        'licencia': licencia,\n",
    "        'tecnicas_preentrenamiento': str_tecnicas,\n",
    "        'descargas': info.downloads,\n",
    "        'tarea_principal': info.pipeline_tag,\n",
    "        'likes': getattr(info, 'likes', 'None'),\n",
    "        'tags': ', '.join(getattr(info, 'tags', 'None'),),\n",
    "        'licencia': licencia\n",
    "    }\n",
    "\n",
    "    return informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "07737380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>autor</th>\n",
       "      <th>tarea</th>\n",
       "      <th>fecha-creacion</th>\n",
       "      <th>fecha-ultima-acualizacion</th>\n",
       "      <th>arquitectura_base</th>\n",
       "      <th>tipo_modelo</th>\n",
       "      <th>parametros</th>\n",
       "      <th>peso_disco</th>\n",
       "      <th>licencia</th>\n",
       "      <th>tecnicas_preentrenamiento</th>\n",
       "      <th>descargas</th>\n",
       "      <th>tarea_principal</th>\n",
       "      <th>likes</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2024-02-19 12:39:28+00:00</td>\n",
       "      <td>RobertaForMaskedLM</td>\n",
       "      <td>roberta</td>\n",
       "      <td>124647170</td>\n",
       "      <td>2684.78 MB (2.62 GB)</td>\n",
       "      <td>mit</td>\n",
       "      <td>Ver Model Card (Texto)</td>\n",
       "      <td>8977612</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>534</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, safetens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/deberta-v3-base</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022-03-02 23:29:05+00:00</td>\n",
       "      <td>2022-09-22 12:34:19+00:00</td>\n",
       "      <td>Desconocida</td>\n",
       "      <td>deberta-v2</td>\n",
       "      <td>184423682</td>\n",
       "      <td>1765.66 MB (1.72 GB)</td>\n",
       "      <td>mit</td>\n",
       "      <td>Ver Model Card (Texto)</td>\n",
       "      <td>1992303</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>376</td>\n",
       "      <td>transformers, pytorch, tf, rust, deberta-v2, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      nombre       autor      tarea            fecha-creacion  \\\n",
       "0    FacebookAI/roberta-base  FacebookAI  fill-mask 2022-03-02 23:29:04+00:00   \n",
       "1  microsoft/deberta-v3-base   microsoft  fill-mask 2022-03-02 23:29:05+00:00   \n",
       "\n",
       "  fecha-ultima-acualizacion   arquitectura_base tipo_modelo  parametros  \\\n",
       "0 2024-02-19 12:39:28+00:00  RobertaForMaskedLM     roberta   124647170   \n",
       "1 2022-09-22 12:34:19+00:00         Desconocida  deberta-v2   184423682   \n",
       "\n",
       "             peso_disco licencia tecnicas_preentrenamiento  descargas  \\\n",
       "0  2684.78 MB (2.62 GB)      mit    Ver Model Card (Texto)    8977612   \n",
       "1  1765.66 MB (1.72 GB)      mit    Ver Model Card (Texto)    1992303   \n",
       "\n",
       "  tarea_principal  likes                                               tags  \n",
       "0       fill-mask    534  transformers, pytorch, tf, jax, rust, safetens...  \n",
       "1       fill-mask    376  transformers, pytorch, tf, rust, deberta-v2, d...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparamos solo esos 2 modelos\n",
    "modelos_comparar = {'FacebookAI/roberta-base', 'microsoft/deberta-v3-base'}\n",
    "comparativa_modelos_finales = obtener_dataframe_informativo(modelos_comparar, obtener_informacion_avanzada)\n",
    "comparativa_modelos_finales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d51d62",
   "metadata": {},
   "source": [
    "**Información básica:**\n",
    "- Nº de parámetros: Una diferencia normalita (~185M de parámetros contra ~125M de parámetros).\n",
    "- Arquitectura base: El más pesado (deberta) tiene una arquitectura desconocida (no se pudo encontrar), pero según Copilot, está basada en RoBERTa (basada en BERT) y roberta, en RobertaForMaskedLM.\n",
    "- Licencia: Ambos tienen la licencia mit (software libre y de código abierto).\n",
    "- Peso del modelo: 1.72 contra 2.62GB. Curioso porque deberta tiene más parámetros que roberta.\n",
    "- Técnicas de pre-entrenamiento: Ambos se pre-entrenaron con la técnica de Masked Language Modeling (MLM)\n",
    "\n",
    "\n",
    "**Información extra recomendada:**\n",
    "- Autor: microsoft y FacebookAI (Dos grandes empresas).\n",
    "- Fecha de creación: Aunque ambos son del mismo año y mes (2022-03-02), roberta está más actualizado (2024 vs 2022).\n",
    "- Descargas: Roberta ha sido probado por mucha más gente (~10M descargas vs ~2M descargas de Deberta).\n",
    "- Ambos no tienen cabezas especializadas (para sentiment-analizer, clasificación, etc).\n",
    "\n",
    "En el PDF se explica más detalladamente las comparaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10636b0d",
   "metadata": {},
   "source": [
    "# 3. Fine-tunning con lora\n",
    "Aplicaremos la técnica de lora para especializar estos modelos sin necesidad de entrenarlos desde cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e7b21",
   "metadata": {},
   "source": [
    "## 3.1. FT para Deberta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283d23f",
   "metadata": {},
   "source": [
    "### 3.1.1. Tokenización de los datos\n",
    "Mediante map (más rápido) y DataCollatorWithPadding (para generar tokens dinámicamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "498f0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para aplicar tokenizado eficiente\n",
    "def tokenizar_datos_deberta(datos):\n",
    "\n",
    "    # Tokenizamos\n",
    "    return token_deberta(\n",
    "        datos['reviews'],\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "925040e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/manu/Desktop/Programacion/Trabajos ciencia datos/MG/.env/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6123ffd54fb349a1b077fedff4383aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f142947b9e5a498db7d34a0c4c40a641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtenemos el modelo\n",
    "nombre_deberta = 'microsoft/deberta-v3-base'\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(nombre_deberta, num_labels=2)\n",
    "\n",
    "# De las 40k de reseñas, dividimos en train y test para simplificar\n",
    "datos_split_deberta = reviews_hugging_face.train_test_split(test_size=0.2, seed=42)\n",
    "train_deberta = datos_split_deberta['train']\n",
    "test_deberta = datos_split_deberta['test']\n",
    "\n",
    "# Obtenemos su tokenizador\n",
    "token_deberta = AutoTokenizer.from_pretrained(nombre_deberta)\n",
    "\n",
    "# Tokenizamos los datos\n",
    "train_deberta_tokenizado = train_deberta.map(tokenizar_datos_deberta, batched=True, remove_columns='reviews')\n",
    "test_deberta_tokenizado = test_deberta.map(tokenizar_datos_deberta, batched=True, remove_columns='reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "393b7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la instancia de DataCollator\n",
    "data_collator_deberta = DataCollatorWithPadding(\n",
    "    tokenizer=token_deberta,\n",
    "    padding=True,\n",
    "    max_length=None,\n",
    "    pad_to_multiple_of=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469509a5",
   "metadata": {},
   "source": [
    "### 3.1.2. Preparamos el modelo para aplicarle LoRA\n",
    "Así no entrenamos todos los parámetros del modelo (~500M) y solo un porcentaje menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "87ad330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabezas de cada capa: 12\n",
      "Formato de guardado de pesos: torch.float32\n",
      "Estructura de roberta:\n",
      " DebertaV2ForSequenceClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pooler): ContextPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Informacion básica de roberta\n",
    "print(f'Cabezas de cada capa: {deberta_model.config.num_attention_heads}')\n",
    "print(f'Formato de guardado de pesos: {deberta_model.dtype}')\n",
    "\n",
    "# Vemos la estructura de roberta\n",
    "print('Estructura de roberta:\\n', deberta_model)  # Esto es especial para saber  como se llaman los vectores q, k y v, a quienes se les aplica esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "adafc501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros totales: [184423682]\n",
      "Parámetros entrenables: 148994\n",
      "Porcentaje de entreno: [0.08078897]\n"
     ]
    }
   ],
   "source": [
    "# Configuramos el LoRA\n",
    "configuracion_lora_deberta = LoraConfig(\n",
    "    r=4,  # Es recomendable comenzar con 8\n",
    "    lora_alpha=32,  # Recomendable el doble o cuadruple que r\n",
    "    target_modules=['query_proj', 'value_proj'],  # Se lo aplicamos a los vectores q y v\n",
    "    lora_dropout=0.1,  # El dropout de siempre\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# Aplicamos LoRA al modelo\n",
    "deberta_model_lora = get_peft_model(deberta_model, configuracion_lora_deberta)\n",
    "\n",
    "# Obtenemos cuantos parametros vamos a entrenar\n",
    "parametros_entrenar_deberta = sum(parametro.numel() for parametro in deberta_model_lora.parameters() if parametro.requires_grad)\n",
    "\n",
    "# Vemos cuanto vamos a entrenar\n",
    "pesos_modelo_deberta = comparativa_modelos_finales[comparativa_modelos_finales['nombre'] == nombre_deberta]['parametros'].values\n",
    "print(f'Parámetros totales: {pesos_modelo_deberta}')\n",
    "print(f'Parámetros entrenables: {parametros_entrenar_deberta}')\n",
    "print(f'Porcentaje de entreno: {(parametros_entrenar_deberta / pesos_modelo_deberta) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d709e5",
   "metadata": {},
   "source": [
    "### 3.1.3. Entrenamos el modelo\n",
    "Lo cual, ¡Solo estaríamos entrenando aproximadamente un 0.16% de los pesos del modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "82d4b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de evaluación\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Esta funcion es del notebook de fine tuning de lora, como nos sirve, hemos decidido reusarla. No hate plis :)\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    # Sacamos predicciones y reales\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Convertir logits a clases predichas (argmax sobre dimensión de clases)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calcular accuracy comparando predicciones con labels verdaderos\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e58676ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los hiperparametros del modelo\n",
    "args_deberta = TrainingArguments(\n",
    "    num_train_epochs=3,  # Con 3 ya se muestra mucha potencia, con 4 o mas puede llegar a overfitting\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    logging_steps=50,\n",
    "    report_to='none',\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Creamos el trainer (como lo que vamos a entrenar)\n",
    "deberta_train = Trainer(\n",
    "    model=deberta_model_lora,\n",
    "    args=args_deberta,\n",
    "    train_dataset=train_deberta_tokenizado,\n",
    "    eval_dataset=test_deberta_tokenizado,\n",
    "    processing_class=token_deberta,\n",
    "    data_collator=data_collator_deberta,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3cdf70",
   "metadata": {},
   "source": [
    "Ahora entrenamos el transformer con LoRA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a546a19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 06:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.451699</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.412557</td>\n",
       "      <td>0.848750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.397587</td>\n",
       "      <td>0.849250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=0.38709563604990643, metrics={'train_runtime': 386.1325, 'train_samples_per_second': 124.31, 'train_steps_per_second': 15.539, 'total_flos': 1642412860862400.0, 'train_loss': 0.38709563604990643, 'epoch': 3.0})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos\n",
    "deberta_train.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fce8c",
   "metadata": {},
   "source": [
    "### 3.1.4. Evaluación del entrenamiento\n",
    "Ahora, vamos a ver algunas métricas con classification_report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0cd688e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      2028\n",
      "           1       0.86      0.83      0.84      1972\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.85      0.85      0.85      4000\n",
      "weighted avg       0.85      0.85      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos las reseñas de test\n",
    "pred_proba_deberta = deberta_train.predict(test_deberta_tokenizado)  # Ya usamos esto como validacion, solo sacaremos mas metricas\n",
    "\n",
    "# Lo convertimos a 1 o 0\n",
    "pred_deberta = np.argmax(pred_proba_deberta.predictions, axis=1)\n",
    "\n",
    "# Mostramos metricas mas avanzadas\n",
    "metricas_deberta_eval = classification_report(y_true=test_deberta['label'], y_pred=pred_deberta)\n",
    "print(metricas_deberta_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e83fa",
   "metadata": {},
   "source": [
    "Vemos que nos da muy buen f1-score, y tambien muy buen accuracy, precision (cuantas reseñas positivas las ha predicho como positivas correctamene) y recall (cuantas reseñas positivas ha detectado). Por lo cual, podemos decir que LoRA funcionó muy bien para esta tarea. Haremos una última prueba poniendo reseñas nosotros: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "18ddbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseñas inventadas\n",
    "reseñas_evaluar = {\n",
    "    'reviews': [\n",
    "        'This game is amazing, althought the first leves are difficult, but then online levels are incredible, specially gaunlets.',\n",
    "        'This poor shit is stressfull. I can`t beat Stereo Madness because the fking cube jumped when I clicked. Delete this game please.',\n",
    "        'Robot took 5 years to give us 2.2, but personally, I think the update is good, but for 5 years, is quite a long time.',\n",
    "        'This game is amazing, but I am noob :( (phobos is hard)'\n",
    "    ],\n",
    "    'label': [1, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Pasamos esto a un dataset de hugging face\n",
    "reseñas_evaluar_hugging = Dataset.from_dict(reseñas_evaluar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4e8c7ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805d709b01e54f11b14c1bf500655752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizamos las reseñas\n",
    "reseñas_eval_token_deberta = reseñas_evaluar_hugging.map(tokenizar_datos_deberta, batched=True, remove_columns='reviews')\n",
    "\n",
    "# Se lo pasamos al modelo\n",
    "pred_proba_eval_deberta = deberta_train.predict(reseñas_eval_token_deberta)\n",
    "\n",
    "# Vemos los resultados\n",
    "pred_eval_deberta = np.argmax(pred_proba_eval_deberta.predictions, axis=1)\n",
    "metricas_deberta_eval_personalizado = classification_report(y_true=pred_proba_eval_deberta.label_ids, y_pred=pred_eval_deberta)\n",
    "print(metricas_deberta_eval_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7718fda",
   "metadata": {},
   "source": [
    "Es verdad que estas reseñas son muy simples, pero aun así ha sido capaz de predecir correctamente. Personalmente le damos un 9/10. Vamos a probar a su competidor roberta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6a148",
   "metadata": {},
   "source": [
    "## 3.2. FT para Roberta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f926c4d",
   "metadata": {},
   "source": [
    "### 3.2.1. Repetimos los mismos pasos\n",
    "No vamos a alargarnos, ya que es hacer lo mismo pero con el otro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b99f9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para aplicar tokenizado eficiente\n",
    "def tokenizar_datos_roberta(datos):\n",
    "\n",
    "    # Tokenizamos\n",
    "    return token_roberta(\n",
    "        datos['reviews'],\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "aa26cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576b33eaf2e5467ba5b19cf9870af6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baac30df40154a6d825067144c53213d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformacion de los datos\n",
    "# Obtenemos el modelo\n",
    "nombre_roberta = 'FacebookAI/roberta-base'\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(nombre_roberta, num_labels=2)\n",
    "\n",
    "# De las 40k de reseñas, dividimos en train y test para simplificar\n",
    "datos_split_roberta = reviews_hugging_face.train_test_split(test_size=0.2, seed=42)\n",
    "train_roberta = datos_split_roberta['train']\n",
    "test_roberta = datos_split_roberta['test']\n",
    "\n",
    "# Obtenemos su tokenizador\n",
    "token_roberta = AutoTokenizer.from_pretrained(nombre_roberta)\n",
    "\n",
    "# Tokenizamos los datos\n",
    "train_roberta_tokenizado = train_roberta.map(tokenizar_datos_roberta, batched=True, remove_columns='reviews')\n",
    "test_roberta_tokenizado = test_roberta.map(tokenizar_datos_roberta, batched=True, remove_columns='reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4e31c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando el datacollator\n",
    "# Creamos la instancia de DataCollator\n",
    "data_collator_roberta = DataCollatorWithPadding(\n",
    "    tokenizer=token_roberta,\n",
    "    padding=True,\n",
    "    max_length=None,\n",
    "    pad_to_multiple_of=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cf591ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabezas de cada capa: 12\n",
      "Formato de guardado de pesos: torch.float32\n",
      "Estructura de roberta:\n",
      " RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Informacion básica de roberta\n",
    "print(f'Cabezas de cada capa: {roberta_model.config.num_attention_heads}')\n",
    "print(f'Formato de guardado de pesos: {roberta_model.dtype}')\n",
    "\n",
    "# Vemos la estructura de roberta\n",
    "print('Estructura de roberta:\\n', roberta_model)  # Esto es especial para saber  como se llaman los vectores q, k y v, a quienes se les aplica esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "14e75675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabezas de cada capa: 12\n",
      "Formato de guardado de pesos: torch.float32\n",
      "Estructura de roberta:\n",
      " RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Informacion básica de roberta\n",
    "print(f'Cabezas de cada capa: {roberta_model.config.num_attention_heads}')\n",
    "print(f'Formato de guardado de pesos: {roberta_model.dtype}')\n",
    "\n",
    "# Vemos la estructura de roberta\n",
    "print('Estructura de roberta:\\n', roberta_model)  # Esto es especial para saber  como se llaman los vectores q, k y v, a quienes se les aplica esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e9c43e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros totales: [124647170]\n",
      "Parámetros entrenables: 813314\n",
      "Porcentaje de entreno: [0.65249295]\n"
     ]
    }
   ],
   "source": [
    "# Configuramos el LoRA\n",
    "configuracion_lora_roberta = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['key', 'query', 'value'],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "# Aplicamos LoRA a roberta\n",
    "roberta_model_lora = get_peft_model(roberta_model, configuracion_lora_roberta)\n",
    "\n",
    "# Obtenemos cuantos parametros vamos a entrenar\n",
    "parametros_entrenar_roberta = sum(parametro.numel() for parametro in roberta_model_lora.parameters() if parametro.requires_grad)\n",
    "\n",
    "# Vemos cuanto vamos a entrenar\n",
    "pesos_modelo_roberta = comparativa_modelos_finales[comparativa_modelos_finales['nombre'] == nombre_roberta]['parametros'].values\n",
    "print(f'Parámetros totales: {pesos_modelo_roberta}')\n",
    "print(f'Parámetros entrenables: {parametros_entrenar_roberta}')\n",
    "print(f'Porcentaje de entreno: {(parametros_entrenar_roberta / pesos_modelo_roberta) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ed2f3",
   "metadata": {},
   "source": [
    "Resaltar que solo entrenamos aproximadamente un 0.71% de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b3f5f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando el entrenamiento\n",
    "# Preparamos los hiperparametros del modelo\n",
    "args_roberta = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='no',\n",
    "    logging_steps=50,\n",
    "    report_to='none',\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Creamos el trainer (como lo que vamos a entrenar)\n",
    "roberta_train = Trainer(\n",
    "    model=roberta_model_lora,\n",
    "    args=args_roberta,\n",
    "    train_dataset=train_roberta_tokenizado,\n",
    "    eval_dataset=test_roberta_tokenizado,\n",
    "    processing_class=token_roberta,\n",
    "    data_collator=data_collator_roberta,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d7b4db02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 04:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.413771</td>\n",
       "      <td>0.835250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.398306</td>\n",
       "      <td>0.843250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.396490</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=0.41176177469889325, metrics={'train_runtime': 248.8027, 'train_samples_per_second': 192.924, 'train_steps_per_second': 24.115, 'total_flos': 1774197131178624.0, 'train_loss': 0.41176177469889325, 'epoch': 3.0})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento de roberta\n",
    "# Entrenamos\n",
    "roberta_train.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1546568",
   "metadata": {},
   "source": [
    "### 3.2.2. Evaluacion del modelo\n",
    "Vamos a ver si funciona o no, viendo métricas como antes lo hicimos con deberta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a72bd5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      2028\n",
      "           1       0.85      0.83      0.84      1972\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.84      0.84      0.84      4000\n",
      "weighted avg       0.84      0.84      0.84      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos las reseñas de test\n",
    "pred_proba_roberta = roberta_train.predict(test_roberta_tokenizado)  # Ya usamos esto como validacion, solo sacaremos mas metricas\n",
    "\n",
    "# Lo convertimos a 1 o 0\n",
    "pred_roberta = np.argmax(pred_proba_roberta.predictions, axis=1)\n",
    "\n",
    "# Mostramos metricas mas avanzadas\n",
    "metricas_roberta_eval = classification_report(y_true=test_roberta['label'], y_pred=pred_roberta)\n",
    "print(metricas_roberta_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a17955",
   "metadata": {},
   "source": [
    "Ahora con las reseñas inventadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1bc5904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195031443a7a47b1afb985b7e7d823b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizamos las reseñas\n",
    "reseñas_eval_token_roberta = reseñas_evaluar_hugging.map(tokenizar_datos_roberta, batched=True, remove_columns='reviews')\n",
    "\n",
    "# Se lo pasamos al modelo\n",
    "pred_proba_eval_roberta = roberta_train.predict(reseñas_eval_token_roberta)\n",
    "\n",
    "# Vemos los resultados\n",
    "pred_eval_roberta = np.argmax(pred_proba_eval_roberta.predictions, axis=1)\n",
    "metricas_roberta_eval_personalizado = classification_report(y_true=pred_proba_eval_roberta.label_ids, y_pred=pred_eval_roberta)\n",
    "print(metricas_roberta_eval_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc4728",
   "metadata": {},
   "source": [
    "Aquí vemos que predice bien las reseñas como deberta. Personalmente le damos un 9/10, porque no hay mucha diferencia en los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd91d1",
   "metadata": {},
   "source": [
    "# 4. Comparación de resultados de ambos modelos\n",
    "Vamos a ver una comparación entre estos 2 modelos, y de paso, explicaremos por qué uno es mejor que otro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "af5dd9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Metricas para deberta ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      2028\n",
      "           1       0.86      0.83      0.84      1972\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.85      0.85      0.85      4000\n",
      "weighted avg       0.85      0.85      0.85      4000\n",
      "\n",
      "=============== Metricas para roberta ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      2028\n",
      "           1       0.85      0.83      0.84      1972\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.84      0.84      0.84      4000\n",
      "weighted avg       0.84      0.84      0.84      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 15, 'Metricas para deberta', '=' * 15)\n",
    "print(metricas_deberta_eval)\n",
    "print('=' * 15, 'Metricas para roberta', '=' * 15)\n",
    "print(metricas_roberta_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb1290",
   "metadata": {},
   "source": [
    "Vemos que empatan en f1 ambos modelos (tanto en f1 macro como weighted, aunque este último no importa mucho al estar **las clases valanceadas**). Pero si somos algo más críticos, vemos que deberta da un poquito mejor f1, aunque insignificante. Lo principal es que, partimos que deberta tiene más parámetros que roberta, y al final, el rendimiento de ambos es por decirlo igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "25dc5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Parametros deberta ===============\n",
      "Parámetros entrenables: 148994\n",
      "Porcentaje de entreno: [0.08078897]\n",
      "=============== Parametros roberta ===============\n",
      "Parámetros entrenables: 813314\n",
      "Porcentaje de entreno: [0.65249295]\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos el numero de parametros entrenados por cada uno\n",
    "print('=' * 15, 'Parametros deberta', '=' * 15)\n",
    "print(f'Parámetros entrenables: {parametros_entrenar_deberta}')\n",
    "print(f'Porcentaje de entreno: {(parametros_entrenar_deberta / pesos_modelo_deberta) * 100}')\n",
    "\n",
    "print('=' * 15, 'Parametros roberta', '=' * 15)\n",
    "print(f'Parámetros entrenables: {parametros_entrenar_roberta}')\n",
    "print(f'Porcentaje de entreno: {(parametros_entrenar_roberta / pesos_modelo_roberta) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e9000",
   "metadata": {},
   "source": [
    "En general, entrenamos menos parametros en deberta, pero investigando, vimos que es porque en Roberta, AutoModelForSequenceClassification 'elimina' una de sus capas y le pone una nueva, la cual es la que usamos para clasificar. En cambio, con Deberta, aprovecha dicha capa y añade la nueva de clasificación. En este caso, no pasó esto, pero podría pasar (seguramente si ejecutan la celda de nuevo) que roberta tenga peores resultdaos (mínimos) que deberta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4de94705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Metricas para deberta ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "=============== Metricas para roberta ===============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 15, 'Metricas para deberta', '=' * 15)\n",
    "print(metricas_deberta_eval_personalizado)\n",
    "print('=' * 15, 'Metricas para roberta', '=' * 15)\n",
    "print(metricas_roberta_eval_personalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e84e7a",
   "metadata": {},
   "source": [
    "Vamos a explicar a detalle los resultados de cada uno:\n",
    "\n",
    "- En cuanto a las métricas con el test, Deberta tiene mejores resultados, dando mejor score a la clase 1 (0.85) que la 0 (0.84). Esto se debe principalmente porque Deberta, se basa en la idea de **mejorar BERT, porque está mal entrenado,** introduciendo algo llamado 'atención desempaquetada,' lo cual, a grandes rasgos, trata de separar los contenidos de la posición de las palabras.\n",
    "- En cuanto a los pesos entrenados, Deberta vuelve a ganar, ya que, al tener más parámetros/pesos/ LoRA hace que, al crear matrices más pequeñas, se utilize un porcentaje, que a lo mejor es similar a Roberta, pero al existir más parámetros/pesos, pues ahí saca la diferencia (0.08% de Deberta vs 0.6% de Roberta, que aún así es poquísimo).\n",
    "- Y en cuanto a las métricas de las reseñas personalizadas, pasa lo mismo que con las métricas de test: Deberta pretende arreglar BERT (o ROBERTA), y de ahñi es que su 'mejora' de mejores resultados en general.\n",
    "\n",
    "Esto se explica mejor en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a22d12",
   "metadata": {},
   "source": [
    "# 5. Extra: Comparación VS otras técnicas (como el prompt engineering)\n",
    "Vamos a ver si vale la pena entrenar estos modelos en frente a otras opciones más asequibles como aplicar técnicas de **prompt engineering**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "95455e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>autor</th>\n",
       "      <th>descargas</th>\n",
       "      <th>funcion</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai-community/gpt2</td>\n",
       "      <td>None</td>\n",
       "      <td>9934564</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, pytorch, tf, jax, tflite, rust,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen/Qwen2.5-7B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>7812528</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen/Qwen2.5-3B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>6100885</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>5221966</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, llama, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen/Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>5087315</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>facebook/opt-125m</td>\n",
       "      <td>None</td>\n",
       "      <td>4492941</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, pytorch, tf, jax, opt, text-gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>3686452</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, llama, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gensyn/Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>3572773</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>None</td>\n",
       "      <td>3275581</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, llama, text-genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Qwen/Qwen2.5-Coder-0.5B-Instruct</td>\n",
       "      <td>None</td>\n",
       "      <td>3142890</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             nombre autor  descargas          funcion  \\\n",
       "0             openai-community/gpt2  None    9934564  text-generation   \n",
       "1          Qwen/Qwen2.5-7B-Instruct  None    7812528  text-generation   \n",
       "2          Qwen/Qwen2.5-3B-Instruct  None    6100885  text-generation   \n",
       "3  meta-llama/Llama-3.1-8B-Instruct  None    5221966  text-generation   \n",
       "4        Qwen/Qwen2.5-1.5B-Instruct  None    5087315  text-generation   \n",
       "5                 facebook/opt-125m  None    4492941  text-generation   \n",
       "6  meta-llama/Llama-3.2-1B-Instruct  None    3686452  text-generation   \n",
       "7      Gensyn/Qwen2.5-0.5B-Instruct  None    3572773  text-generation   \n",
       "8           meta-llama/Llama-3.2-1B  None    3275581  text-generation   \n",
       "9  Qwen/Qwen2.5-Coder-0.5B-Instruct  None    3142890  text-generation   \n",
       "\n",
       "                                                tags  \n",
       "0  [transformers, pytorch, tf, jax, tflite, rust,...  \n",
       "1  [transformers, safetensors, qwen2, text-genera...  \n",
       "2  [transformers, safetensors, qwen2, text-genera...  \n",
       "3  [transformers, safetensors, llama, text-genera...  \n",
       "4  [transformers, safetensors, qwen2, text-genera...  \n",
       "5  [transformers, pytorch, tf, jax, opt, text-gen...  \n",
       "6  [transformers, safetensors, llama, text-genera...  \n",
       "7  [transformers, safetensors, qwen2, text-genera...  \n",
       "8  [transformers, safetensors, llama, text-genera...  \n",
       "9  [transformers, safetensors, qwen2, text-genera...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo que vamos a usar\n",
    "mejores_modelos_decoder = list(\n",
    "        list_models(\n",
    "        filter=['text-generation', 'en'],\n",
    "        sort='downloads',\n",
    "        direction=-1,\n",
    "        limit=10\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sacamos informacion importante\n",
    "info_modelos_genrativos = {\n",
    "    'nombre': [modelo.id for modelo in mejores_modelos_decoder],\n",
    "    'autor': [modelo.author for modelo in mejores_modelos_decoder],\n",
    "    'descargas': [modelo.downloads for modelo in mejores_modelos_decoder],\n",
    "    'funcion': [modelo.pipeline_tag for modelo in mejores_modelos_decoder],\n",
    "    'tags': [modelo.tags for modelo in mejores_modelos_decoder]\n",
    "}\n",
    "\n",
    "# Mostramos en un dataframe\n",
    "df_modelos_decoder = pd.DataFrame(info_modelos_genrativos)\n",
    "df_modelos_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d521d2",
   "metadata": {},
   "source": [
    "Vamos a quedarnos con Qwen2.5-7B-Instruct, según chatgpt es el mejor candidato para prompt engineering:\n",
    "\n",
    "**Mejor equilibrio (para reseñas coloquiales con prompt engineering):**\n",
    "\n",
    "- Qwen2.5-7B-Instruct → potencia y buena comprensión de inglés coloquial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "dc431e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos vamos a quedar co\n",
    "modelo_usar = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "token_decoder = AutoTokenizer.from_pretrained(modelo_usar)\n",
    "token_decoder.pad_token = token_decoder.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc05286",
   "metadata": {},
   "source": [
    "## 5.1. Zero-shot\n",
    "Vamos a coger un modelo generativo tipo decoder, y vamos a aplicarle la técnica de prompt engineering (sin poner ejemplos), y veremos que tal le va contra el dataset y las reseñas inventadas por nosotros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "73fd1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a obtener las reseñas\n",
    "reseñas_usar = reviews_dataframe['reviews'].iloc[:60]  # Solo 60 porque sino se tarda mucho\n",
    "label = reviews_dataframe['label'].iloc[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72337bdb",
   "metadata": {},
   "source": [
    "Vamos a configurarlo para poder usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a75a0fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678b55558f2b4d2c8c9788df67a094f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuramos el modelo\n",
    "zero_shot = pipeline(\n",
    "    model=modelo_usar,\n",
    "    tokenizer=token_decoder,\n",
    "    task='text-generation',\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Configuramos el modelo\n",
    "configuracion_zero_shot = {\n",
    "    'max_new_tokens': 45,\n",
    "    'temperature': 0.05,\n",
    "    'top_k': 10,\n",
    "    'top_p': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f2295",
   "metadata": {},
   "source": [
    "Vamos a ver que resultados nos genera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bbcfb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para obtener las respuestas\n",
    "def obtener_predicciones_chunk(chunk_reseñas, samples={}):\n",
    "\n",
    "    # Las pasamos a string\n",
    "    reseñas_chunk_string = '\\n'.join(['\\t- ' + reseña.replace('\\n', '') for reseña in chunk_reseñas])\n",
    "\n",
    "    # Si queremos ejemplos, los configuramos para metelo al prompt\n",
    "    if len(samples) != 0:\n",
    "        samples = '' + '\\n'.join([f'- Review: {fila[\"reviews\"]}, Prediction: {fila[\"label\"]}' for fila in samples])\n",
    "        samples = f'''\n",
    "\n",
    "    ### SOME EXAMPLES\n",
    "    {samples}\n",
    "\n",
    "    ---\n",
    "    '''\n",
    "    \n",
    "    else:\n",
    "        samples = ''\n",
    "\n",
    "    # Prompt a usar\n",
    "    prompt_usar = f\"\"\"\\n\n",
    "    =========PROMPT============\n",
    "    You are a strict binary classification system. Follow the rules EXACTLY.\n",
    "\n",
    "    ### TASK\n",
    "    Classify the following {len(chunk_reseñas)} reviews into:\n",
    "    - `0` = negative\n",
    "    - `1` = positive\n",
    "\n",
    "    ### INPUT (exactly {len(chunk_reseñas)} reviews):\n",
    "    {reseñas_chunk_string}\n",
    "\n",
    "    ---\n",
    "    {samples}\n",
    "    ### RULES (MUST FOLLOW)\n",
    "    - Output MUST contain **exactly {len(chunk_reseñas)} values**.\n",
    "    - Each value MUST be only `0` or `1`.\n",
    "    - Values MUST be separated by commas with NO spaces.\n",
    "    - NO text before.\n",
    "    - NO text after.\n",
    "    - NO explanation.\n",
    "    - NO formatting.\n",
    "    - NO markdown.\n",
    "    - NO additional symbols.\n",
    "    - NO quotes.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### FINAL INSTRUCTION\n",
    "    Respond ONLY with the {len(chunk_reseñas)} comma-separated digits. NOTHING ELSE.\\n\n",
    "    =========END of PROMPT============\n",
    "    \"\"\"\n",
    "\n",
    "    # Pasamos esto al modelo\n",
    "    resultado_zero_shot = zero_shot (\n",
    "        prompt_usar,\n",
    "        num_return_sequences=1,\n",
    "        **configuracion_zero_shot\n",
    "    )\n",
    "\n",
    "    # Obtenemos la respuesta\n",
    "    resultado_generado_zero_shot = resultado_zero_shot[0]['generated_text'].strip()\n",
    "\n",
    "    # Extraemos la lista de predicciones\n",
    "    match = re.search(r'[01](?:,[01])+', resultado_generado_zero_shot)\n",
    "\n",
    "    # Vemos que nos la haya devuelto bien\n",
    "    if match:\n",
    "        pred_list = list(map(int, match.group().split(',')))\n",
    "        return pred_list\n",
    "\n",
    "    else:\n",
    "        print(f'Fallo: {resultado_generado_zero_shot}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "19b20169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que se encarga que se devuelva si o si un vector de predicciones\n",
    "def obtener_predicciones_chunk_correctas(chunk_reseñas, samples={}):\n",
    "\n",
    "    # Obtenemos los resultados\n",
    "    resultados_chunk = obtener_predicciones_chunk(chunk_reseñas, samples)\n",
    "\n",
    "    # Nos aseguramos que no sea None\n",
    "    correcto = resultados_chunk is not None\n",
    "    while not correcto:\n",
    "        resultados_chunk = obtener_predicciones_chunk(chunk_reseñas, samples)\n",
    "        correcto = resultados_chunk is not None\n",
    "\n",
    "    # Devolvemos el vector\n",
    "    return resultados_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas predicciones del chunk 0: [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "Nuevas predicciones del chunk 15: [0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Nuevas predicciones del chunk 30: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "Nuevas predicciones del chunk 45: [1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los resultados\n",
    "resultados = list()\n",
    "chunk = 15\n",
    "\n",
    "# Pasamos las reseñas en chunks\n",
    "for i in range(0, reseñas_usar.shape[0], chunk):\n",
    "\n",
    "    # Sacamos el chunk\n",
    "    reseñas_chunk = reseñas_usar.iloc[i:i+chunk]\n",
    "\n",
    "    # Pedimos respuesta al modelo\n",
    "    prediccion_completa = False\n",
    "    lista_prediccion_zero_shot = obtener_predicciones_chunk_correctas(reseñas_chunk)\n",
    "    print(f'Nuevas predicciones del chunk {i}: {lista_prediccion_zero_shot}')\n",
    "\n",
    "    # Actualizamos lista\n",
    "    resultados += lista_prediccion_zero_shot\n",
    "\n",
    "# Mostramos el resultado final\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecc685",
   "metadata": {},
   "source": [
    "Vamos a ver como le fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a12e5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72        30\n",
      "           1       0.76      0.53      0.63        30\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.70      0.68      0.68        60\n",
      "weighted avg       0.70      0.68      0.68        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=label, y_pred=resultados))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1cf9a",
   "metadata": {},
   "source": [
    "Y con nuestro dataset inventado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "78ac8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pedimos respuesta al modelo\n",
    "lista_prediccion_zero_shot = obtener_predicciones_chunk_correctas(reseñas_evaluar['reviews'])\n",
    "\n",
    "# Mostramos el resultado final\n",
    "print(lista_prediccion_zero_shot)\n",
    "\n",
    "# Mostramos las metricas\n",
    "print(classification_report(y_true=reseñas_evaluar['label'], y_pred=lista_prediccion_zero_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f43bb8",
   "metadata": {},
   "source": [
    "Pues vemos que en verdad, le fue algo mal (o no servimos para prompt engineering). En conclusión, con Zero-shot, vale la pena entrenar el modelo. Vamos a ver ahora con few shot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfcc6e",
   "metadata": {},
   "source": [
    "## 5.2. Few-shot\n",
    "Vamos a aplicar la técnica de prompt engineering (poner algunos ejemplos), y veremos que tal le va contra el dataset y las reseñas inventadas por nosotros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "615eeb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reviews': 'I lost all my gameplay after the update was released (',\n",
       "  'label': 1},\n",
       " {'reviews': 'bad stupiud baD, O;PTION FOR CHECKPOINTS (SPOILER: THERE IS NON) NOT ADVISED FOR TWITCHY FINGERED PLAYERS OR YOU WILL DIE AND DIE AND DIE FOR 6 YEARS STRAIGHT BECAUSE ITS STUPIUD',\n",
       "  'label': 0},\n",
       " {'reviews': 'i came to this game many times and now my keyboard stopped working jerking jason out...',\n",
       "  'label': 1},\n",
       " {'reviews': 'shit fuck this game', 'label': 0},\n",
       " {'reviews': 'BEST GAME', 'label': 1}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sacamos algunos ejemplos\n",
    "n_samples = 5  # Esto se puede cambiar\n",
    "examples = reviews_dataframe.iloc[:n_samples, :]\n",
    "\n",
    "# Lo pasamos a dict\n",
    "examples_few_shot = examples.to_dict(orient=\"records\")\n",
    "examples_few_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744a3d1",
   "metadata": {},
   "source": [
    "Sacafos los ejemplos, es el mismo proceso que para zero-shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6acd02e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas predicciones del chunk 0: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "Nuevas predicciones del chunk 15: [0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Nuevas predicciones del chunk 30: [1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "Nuevas predicciones del chunk 45: [1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los resultados\n",
    "resultados = list()\n",
    "chunk = 15\n",
    "\n",
    "# Pasamos las reseñas en chunks\n",
    "for i in range(0, reseñas_usar.shape[0], chunk):\n",
    "\n",
    "    # Sacamos el chunk\n",
    "    reseñas_chunk = reseñas_usar.iloc[i:i+chunk]\n",
    "\n",
    "    # Pedimos respuesta al modelo\n",
    "    prediccion_completa = False\n",
    "    lista_prediccion_zero_shot = obtener_predicciones_chunk_correctas(reseñas_chunk, examples_few_shot)\n",
    "    print(f'Nuevas predicciones del chunk {i}: {lista_prediccion_zero_shot}')\n",
    "\n",
    "    # Actualizamos lista\n",
    "    resultados += lista_prediccion_zero_shot\n",
    "\n",
    "# Mostramos el resultado final\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f7550",
   "metadata": {},
   "source": [
    "Vemos que tal le fue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "32f0c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        30\n",
      "           1       0.80      0.67      0.73        30\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.76      0.75      0.75        60\n",
      "weighted avg       0.76      0.75      0.75        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=label, y_pred=resultados))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef48c38",
   "metadata": {},
   "source": [
    "Y con nuestro dataset inventado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6dfa7379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pedimos respuesta al modelo\n",
    "lista_prediccion_zero_shot = obtener_predicciones_chunk_correctas(reseñas_evaluar['reviews'])\n",
    "\n",
    "# Mostramos el resultado final\n",
    "print(lista_prediccion_zero_shot)\n",
    "\n",
    "# Mostramos las metricas\n",
    "print(classification_report(y_true=reseñas_evaluar['label'], y_pred=lista_prediccion_zero_shot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3b03c",
   "metadata": {},
   "source": [
    "Mejoró una barbaridad con respecto a zero-shot, pero aún así, Deberta y Roberta, con su fine-tunning, tienen mejores mñetricas en general (en especial, con nuestras reseñas personalizadas), pero no es descartable usar few-shot para esto. Seguramente si usamos técnicas como 'chain of thought', 'tree of thought' 'RA (reason and act)' o similares, a lo mejor obtenemos mejores resultados. Para esta práctica, zero y few shot nos basta (encima que era una extensión)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e1cfa",
   "metadata": {},
   "source": [
    "# 6. Conclusiones\n",
    "Vimos que LoRA es una técnica muy útil ya que nos permite usar y personalizar (especializar) modelos transformer buenos sin necesidad de usar un hardware y recursos exagerados. Comparado con técnicas de prompt engineering, al menos, en el caso de reseñas coloquiales (muy coloquiales), resulta mucho más beneficioso realizar un entrenamiento LoRA que aplicar algunas técnicas de prompt engineering como zero o few-shot (cero o algunos ejemplos)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

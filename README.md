# âš”ï¸ NLP Avanzado: Steam Reviews & BASH Assistant

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20Transformers-DeBERTa%20%7C%20RoBERTa%20%7C%20Phi--3-yellow)
![Steam](https://img.shields.io/badge/Data-Steam%20Reviews-black?logo=steam)
![Status](https://img.shields.io/badge/Status-Completed-success)

> **ImplementaciÃ³n de tÃ©cnicas SOTA en NLP: Fine-Tuning eficiente (LoRA) para anÃ¡lisis de sentimiento en videojuegos y arquitectura RAG modular para asistencia tÃ©cnica en Linux.**

---

## ğŸ“– DescripciÃ³n del Proyecto

Este repositorio explora dos paradigmas fundamentales del Procesamiento del Lenguaje Natural moderno aplicados a casos de uso reales:

1.  **ClasificaciÃ³n de Opiniones (LoRA):** Â¿Puede un modelo entender la frustraciÃ³n de un jugador de *Geometry Dash*? Entrenamos modelos para distinguir reseÃ±as positivas de negativas.
2.  **Asistente TÃ©cnico (RAG):** Un sistema experto capaz de responder dudas sobre comandos de **BASH** consultando un manual oficial, reduciendo las alucinaciones de los LLMs.

---

## ğŸš€ MÃ³dulo 1: LoRA Fine-Tuning (Geometry Dash Reviews)

Extrajimos reseÃ±as reales de Steam del juego **Geometry Dash (ID: 322170)** para entrenar un clasificador de sentimientos robusto.

* **El Reto:** El lenguaje "gamer" es complejo, lleno de jerga, ironÃ­a y memes (ej. *"Phobos is hard but I am noob"*).
* **La SoluciÃ³n:** Aplicar **LoRA (Low-Rank Adaptation)** a modelos base potentes para especializarlos sin reentrenar todos sus parÃ¡metros.

### ğŸ› ï¸ Modelos y ConfiguraciÃ³n
| Modelo Base | ConfiguraciÃ³n LoRA | Params Entrenables | Resultados (F1-Score) |
| :--- | :--- | :--- | :--- |
| **Microsoft DeBERTa v3** | `r=4`, `alpha=32`, `dropout=0.1` | **~0.15%** | â­ **Muy Alto** |
| **Facebook RoBERTa** | `r=4`, `alpha=32`, `dropout=0.1` | **~0.65%** | â­ **Alto** |

> **Nota:** Se comparÃ³ el rendimiento entrenando solo las matrices de proyecciÃ³n (`query`, `value`, `key`), logrando resultados de nivel profesional con una fracciÃ³n del coste computacional.

---

## ğŸ“š MÃ³dulo 2: Sistema RAG (BASH Manual)

ImplementaciÃ³n "from-scratch" de un sistema de **Retrieval-Augmented Generation** para consultar el manual de referencia de GNU Bash (`manual_bash.txt`).

A diferencia de las librerÃ­as estÃ¡ndar, aquÃ­ implementamos la **lÃ³gica de recuperaciÃ³n manualmente** para entender las matemÃ¡ticas detrÃ¡s del RAG.

### âš™ï¸ Arquitectura del Pipeline
1.  **Ingesta:** Lectura y limpieza del `manual_bash.txt`.
2.  **Chunking:** DivisiÃ³n inteligente del texto con solapamiento (`GeneradorChunks`).
3.  **Embeddings:** VectorizaciÃ³n usando `jina-embeddings-v2-base-es` o `paraphrase-multilingual-mpnet`.
4.  **Retrieval:** BÃºsqueda por **Similitud del Coseno** (implementaciÃ³n propia con NumPy/Scikit-Learn).
5.  **GeneraciÃ³n:** Comparativa entre **Microsoft Phi-3.5** y **Qwen 2.5-1.5B**.

### ğŸ†š Comparativa: Qwen vs Phi-3.5

**Pregunta:** *"Â¿QuÃ© hace el comando grep en Bash?"*

| Modelo | Respuesta Generada | Calidad |
| :--- | :--- | :--- |
| **Qwen 2.5** | Explica detalladamente el uso de expresiones regulares y opciones como `-n` o `-i`. | ğŸŸ¢ **Muy detallada** |
| **Phi-3.5** | Resumen conciso sobre buscar patrones y aclara quÃ© *no* hace (ej. no comprime archivos). | ğŸŸ¡ **Directa y concisa** |

*(Puedes ver los logs completos en la carpeta `results/`)*

---

## ğŸ“‚ Estructura del Repositorio

```bash
â”œâ”€â”€ data/

â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ LoRA.ipynb            # ExtracciÃ³n Steam + Fine-Tuning (DeBERTa/RoBERTa)
â”‚   â”œâ”€â”€ RAG.ipynb             # Pipeline RAG artesanal con Phi-3.5/Qwen
â”‚   â””â”€â”€ manual_bash.txt       # Corpus de conocimiento para el RAG
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ respuestas_normal.txt   # Logs de ejecuciÃ³n con Qwen
â”‚   â””â”€â”€ respuestas_especial.txt # Logs de ejecuciÃ³n con Phi-3.5
â”œâ”€â”€ requirements.txt          # Dependencias (transformers, peft, steam-reviews)
â””â”€â”€ README.md
